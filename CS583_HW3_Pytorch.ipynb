{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "def to_var(tensor, cuda):\n",
    "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
    "\n",
    "        Arguments:\n",
    "            tensor: A Tensor object.\n",
    "            cuda: A boolean flag indicating whether to use the GPU.\n",
    "\n",
    "        Returns:\n",
    "            A Variable object, on the GPU if cuda==True.\n",
    "    \"\"\"\n",
    "    if cuda:\n",
    "        return Variable(tensor.cuda())\n",
    "    else:\n",
    "        return Variable(tensor)\n",
    "\n",
    "\n",
    "def create_dir_if_not_exists(directory):\n",
    "    \"\"\"Creates a directory if it doesn't already exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def save_loss_plot(train_losses, val_losses, opts):\n",
    "    \"\"\"Saves a plot of the training and validation loss curves.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses)\n",
    "    plt.plot(range(len(val_losses)), val_losses)\n",
    "    plt.title('BS={}, nhid={}'.format(opts.batch_size, opts.hidden_size), fontsize=20)\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(opts.checkpoint_path, 'loss_plot.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def checkpoint(encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Saves the current encoder and decoder models, along with idx_dict, which\n",
    "    contains the char_to_index and index_to_char mappings, and the start_token\n",
    "    and end_token values.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(opts.checkpoint_path, 'encoder.pt'), 'wb') as f:\n",
    "        torch.save(encoder, f)\n",
    "\n",
    "    with open(os.path.join(opts.checkpoint_path, 'decoder.pt'), 'wb') as f:\n",
    "        torch.save(decoder, f)\n",
    "\n",
    "    with open(os.path.join(opts.checkpoint_path, 'idx_dict.pkl'), 'wb') as f:\n",
    "        pkl.dump(idx_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(filename):\n",
    "    \"\"\"Read a file and split it into lines.\n",
    "    \"\"\"\n",
    "    lines = open(filename).read().strip().lower().split('\\n')\n",
    "    return lines\n",
    "\n",
    "\n",
    "def read_pairs(filename):\n",
    "    \"\"\"Reads lines that consist of two words, separated by a space.\n",
    "\n",
    "    Returns:\n",
    "        source_words: A list of the first word in each line of the file.\n",
    "        target_words: A list of the second word in each line of the file.\n",
    "    \"\"\"\n",
    "    lines = read_lines(filename)\n",
    "    source_words, target_words = [], []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            source, target = line.split()\n",
    "            source_words.append(source)\n",
    "            target_words.append(target)\n",
    "    return source_words, target_words\n",
    "\n",
    "\n",
    "def all_alpha_or_dash(s):\n",
    "    \"\"\"Helper function to check whether a string is alphabetic, allowing dashes '-'.\n",
    "    \"\"\"\n",
    "    return all(c.isalpha() or c == '-' for c in s)\n",
    "\n",
    "\n",
    "def filter_lines(lines):\n",
    "    \"\"\"Filters lines to consist of only alphabetic characters or dashes \"-\".\n",
    "    \"\"\"\n",
    "    return [line for line in lines if all_alpha_or_dash(line)]\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads (English, Pig-Latin) word pairs, and creates mappings from characters to indexes.\n",
    "    \"\"\"\n",
    "\n",
    "    source_lines, target_lines = read_pairs('data.txt')\n",
    "\n",
    "    # Filter lines\n",
    "    source_lines = filter_lines(source_lines)\n",
    "    target_lines = filter_lines(target_lines)\n",
    "\n",
    "    all_characters = set(''.join(source_lines)) | set(''.join(target_lines))\n",
    "\n",
    "    # Create a dictionary mapping each character to a unique index\n",
    "    char_to_index = { char: index for (index, char) in enumerate(sorted(list(all_characters))) }\n",
    "\n",
    "    # Add start and end tokens to the dictionary\n",
    "    start_token = len(char_to_index)\n",
    "    end_token = len(char_to_index) + 1\n",
    "    char_to_index['SOS'] = start_token\n",
    "    char_to_index['EOS'] = end_token\n",
    "\n",
    "    # Create the inverse mapping, from indexes to characters (used to decode the model's predictions)\n",
    "    index_to_char = { index: char for (char, index) in char_to_index.items() }\n",
    "\n",
    "    # Store the final size of the vocabulary\n",
    "    vocab_size = len(char_to_index)\n",
    "\n",
    "    line_pairs = list(set(zip(source_lines, target_lines)))  # Python 3\n",
    "\n",
    "    idx_dict = { 'char_to_index': char_to_index,\n",
    "                 'index_to_char': index_to_char,\n",
    "                 'start_token': start_token,\n",
    "                 'end_token': end_token }\n",
    "\n",
    "    return line_pairs, vocab_size, idx_dict\n",
    "\n",
    "\n",
    "def create_dict(pairs):\n",
    "    \"\"\"Creates a mapping { (source_length, target_length): [list of (source, target) pairs]\n",
    "    This is used to make batches: each batch consists of two parallel tensors, one containing\n",
    "    all source indexes and the other containing all corresponding target indexes.\n",
    "    Within a batch, all the source words are the same length, and all the target words are\n",
    "    the same length.\n",
    "    \"\"\"\n",
    "    unique_pairs = list(set(pairs))  # Find all unique (source, target) pairs\n",
    "\n",
    "    d = defaultdict(list)\n",
    "    for (s,t) in unique_pairs:\n",
    "        d[(len(s), len(t))].append((s,t))\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_index_list(s, char_to_index, end_token):\n",
    "    \"\"\"Converts a sentence into a list of indexes (for each character).\n",
    "    \"\"\"\n",
    "    return [char_to_index[char] for char in s] + [end_token]  # Adds the end token to each index list\n",
    "\n",
    "\n",
    "def translate_sentence(sentence, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
    "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
    "    word independently, and then stitching the words back together with spaces between them.\n",
    "    \"\"\"\n",
    "    if idx_dict is None:\n",
    "      line_pairs, vocab_size, idx_dict = load_data()\n",
    "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
    "\n",
    "\n",
    "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a given string from English to Pig-Latin.\n",
    "    \"\"\"\n",
    "\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "\n",
    "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
    "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
    "\n",
    "    encoder_annotations, encoder_last_hidden = encoder(indexes)\n",
    "\n",
    "    decoder_hidden = encoder_last_hidden\n",
    "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
    "    decoder_inputs = decoder_input\n",
    "\n",
    "    for i in range(max_generated_chars):\n",
    "      ## slow decoding, recompute everything at each time\n",
    "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
    "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
    "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
    "      ni = ni[-1] #latest output token\n",
    "\n",
    "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
    "      \n",
    "      if ni == end_token:\n",
    "          break\n",
    "      else:\n",
    "          gen_string = \"\".join(\n",
    "              [index_to_char[int(item)] \n",
    "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
    "\n",
    "    return gen_string\n",
    "\n",
    "\n",
    "def visualize_attention(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Generates a heatmap to show where attention is focused in each decoder step.\n",
    "    \"\"\"\n",
    "    if idx_dict is None:\n",
    "      line_pairs, vocab_size, idx_dict = load_data()\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "\n",
    "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
    "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
    "\n",
    "    encoder_annotations, encoder_hidden = encoder(indexes)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
    "    decoder_inputs = decoder_input\n",
    "\n",
    "    produced_end_token = False\n",
    "\n",
    "    for i in range(max_generated_chars):\n",
    "      ## slow decoding, recompute everything at each time\n",
    "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
    "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
    "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
    "      ni = ni[-1] #latest output token\n",
    "      \n",
    "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
    "      \n",
    "      if ni == end_token:\n",
    "          break\n",
    "      else:\n",
    "          gen_string = \"\".join(\n",
    "              [index_to_char[int(item)] \n",
    "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
    "    \n",
    "    if isinstance(attention_weights, tuple):\n",
    "      ## transformer's attention mweights\n",
    "      attention_weights, self_attention_weights = attention_weights\n",
    "    \n",
    "    all_attention_weights = attention_weights.data.cpu().numpy()\n",
    "    \n",
    "    for i in range(len(all_attention_weights)):\n",
    "      attention_weights_matrix = all_attention_weights[i].squeeze()\n",
    "      fig = plt.figure()\n",
    "      ax = fig.add_subplot(111)\n",
    "      cax = ax.matshow(attention_weights_matrix, cmap='bone')\n",
    "      fig.colorbar(cax)\n",
    "\n",
    "      # Set up axes\n",
    "      ax.set_yticklabels([''] + list(input_string) + ['EOS'], rotation=90)\n",
    "      ax.set_xticklabels([''] + list(gen_string) + (['EOS'] if produced_end_token else []))\n",
    "\n",
    "      # Show label at every tick\n",
    "      ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "      ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "      # Add title\n",
    "      plt.xlabel('Attention weights to the source sentence in layer {}'.format(i+1))\n",
    "      plt.tight_layout()\n",
    "      plt.grid('off')\n",
    "      plt.show()\n",
    "      #plt.savefig(save)\n",
    "\n",
    "      #plt.close(fig)\n",
    "\n",
    "    return gen_string\n",
    "\n",
    "\n",
    "def compute_loss(data_dict, encoder, decoder, idx_dict, criterion, optimizer, opts):\n",
    "    \"\"\"Train/Evaluate the model on a dataset.\n",
    "\n",
    "    Arguments:\n",
    "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        optimizer: Train the weights if an optimizer is given. None if only evaluate the model. \n",
    "        opts: The command-line arguments.\n",
    "\n",
    "    Returns:\n",
    "        mean_loss: The average loss over all batches from data_dict.\n",
    "    \"\"\"\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    losses = []\n",
    "    for key in data_dict:\n",
    "        input_strings, target_strings = zip(*data_dict[key])\n",
    "        input_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in input_strings]\n",
    "        target_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in target_strings]\n",
    "\n",
    "        num_tensors = len(input_tensors)\n",
    "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "\n",
    "        for i in range(num_batches):\n",
    "\n",
    "            start = i * opts.batch_size\n",
    "            end = start + opts.batch_size\n",
    "\n",
    "            inputs = to_var(torch.stack(input_tensors[start:end]), opts.cuda)\n",
    "            targets = to_var(torch.stack(target_tensors[start:end]), opts.cuda)\n",
    "\n",
    "            # The batch size may be different in each epoch\n",
    "            BS = inputs.size(0)\n",
    "\n",
    "            encoder_annotations, encoder_hidden = encoder(inputs)\n",
    "\n",
    "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            start_vector = torch.ones(BS).long().unsqueeze(1) * start_token  # BS x 1 --> 16x1  CHECKED\n",
    "            decoder_input = to_var(start_vector, opts.cuda)  # BS x 1 --> 16x1  CHECKED\n",
    "\n",
    "            loss = 0.0\n",
    "\n",
    "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
    "\n",
    "            decoder_inputs = torch.cat([decoder_input, targets[:, 0:-1]], dim=1)  # Gets decoder inputs by shifting the targets to the right \n",
    "            \n",
    "            decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, encoder_hidden)\n",
    "            decoder_outputs_flatten = decoder_outputs.view(-1, decoder_outputs.size(2))\n",
    "            targets_flatten = targets.view(-1)\n",
    "            loss = criterion(decoder_outputs_flatten, targets_flatten)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            ## training if an optimizer is provided\n",
    "            if optimizer:\n",
    "              # Zero gradients\n",
    "              optimizer.zero_grad()\n",
    "              # Compute gradients\n",
    "              loss.backward()\n",
    "              # Update the parameters of the encoder and decoder\n",
    "              optimizer.step()\n",
    "              \n",
    "    mean_loss = np.mean(losses)\n",
    "    return mean_loss\n",
    "\n",
    "  \n",
    "\n",
    "def training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts):\n",
    "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
    "        * Prints training and val loss each epoch.\n",
    "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
    "        * Saves an attention map for TEST_WORD_ATTN each epoch\n",
    "\n",
    "    Arguments:\n",
    "        train_dict: The training word pairs, organized by source and target lengths.\n",
    "        val_dict: The validation word pairs, organized by source and target lengths.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        optimizer: Implements a step rule to update the parameters of the encoder and decoder.\n",
    "        opts: The command-line arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    loss_log = open(os.path.join(opts.checkpoint_path, 'loss_log.txt'), 'w')\n",
    "\n",
    "    best_val_loss = 1e6\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(opts.nepochs):\n",
    "\n",
    "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "        \n",
    "        train_loss = compute_loss(train_dict, encoder, decoder, idx_dict, criterion, optimizer, opts)\n",
    "        val_loss = compute_loss(val_dict, encoder, decoder, idx_dict, criterion, None, opts)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            checkpoint(encoder, decoder, idx_dict, opts)\n",
    "\n",
    "        gen_string = translate_sentence(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
    "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, train_loss, val_loss, gen_string))\n",
    "\n",
    "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
    "        loss_log.flush()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        save_loss_plot(train_losses, val_losses, opts)\n",
    "\n",
    "\n",
    "def print_data_stats(line_pairs, vocab_size, idx_dict):\n",
    "    \"\"\"Prints example word pairs, the number of data points, and the vocabulary.\n",
    "    \"\"\"\n",
    "    print('=' * 80)\n",
    "    print('Data Stats'.center(80))\n",
    "    print('-' * 80)\n",
    "    for pair in line_pairs[:5]:\n",
    "        print(pair)\n",
    "    print('Num unique word pairs: {}'.format(len(line_pairs)))\n",
    "    print('Vocabulary: {}'.format(idx_dict['char_to_index'].keys()))\n",
    "    print('Vocab size: {}'.format(vocab_size))\n",
    "    print('=' * 80)\n",
    "\n",
    "\n",
    "def train(opts):\n",
    "    line_pairs, vocab_size, idx_dict = load_data()\n",
    "    print_data_stats(line_pairs, vocab_size, idx_dict)\n",
    "\n",
    "    # Split the line pairs into an 80% train and 20% val split\n",
    "    num_lines = len(line_pairs)\n",
    "    num_train = int(0.8 * num_lines)\n",
    "    train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
    "\n",
    "    # Group the data by the lengths of the source and target words, to form batches\n",
    "    train_dict = create_dict(train_pairs)\n",
    "    val_dict = create_dict(val_pairs)\n",
    "\n",
    "    ##########################################################################\n",
    "    ### Setup: Create Encoder, Decoder, Learning Criterion, and Optimizers ###\n",
    "    ##########################################################################\n",
    "    encoder = GRUEncoder(vocab_size=vocab_size, \n",
    "                         hidden_size=opts.hidden_size, \n",
    "                         opts=opts)\n",
    "\n",
    "    if opts.decoder_type == 'rnn':\n",
    "        decoder = RNNDecoder(vocab_size=vocab_size, \n",
    "                             hidden_size=opts.hidden_size)\n",
    "    elif opts.decoder_type == 'rnn_attention':\n",
    "        decoder = RNNAttentionDecoder(vocab_size=vocab_size, \n",
    "                                      hidden_size=opts.hidden_size, \n",
    "                                      attention_type=opts.attention_type)\n",
    "    elif opts.decoder_type == 'transformer':\n",
    "        decoder = TransformerDecoder(vocab_size=vocab_size, \n",
    "                                     hidden_size=opts.hidden_size, \n",
    "                                     num_layers=opts.num_transformer_layers)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    #### setup checkpoint path\n",
    "    model_name = 'h{}-bs{}-{}'.format(opts.hidden_size, \n",
    "                                      opts.batch_size, \n",
    "                                      opts.decoder_type)\n",
    "    opts.checkpoint_path = model_name\n",
    "    create_dir_if_not_exists(opts.checkpoint_path)\n",
    "    ####\n",
    "\n",
    "    if opts.cuda:\n",
    "        encoder.cuda()\n",
    "        decoder.cuda()\n",
    "        print(\"Moved models to GPU!\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=opts.learning_rate)\n",
    "\n",
    "    try:\n",
    "        training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exiting early from training.')\n",
    "        return encoder, decoder\n",
    "      \n",
    "    return encoder, decoder\n",
    "\n",
    "\n",
    "def print_opts(opts):\n",
    "    \"\"\"Prints the values of all command-line arguments.\n",
    "    \"\"\"\n",
    "    print('=' * 80)\n",
    "    print('Opts'.center(80))\n",
    "    print('-' * 80)\n",
    "    for key in opts.__dict__:\n",
    "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, opts):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.opts = opts\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.gru = nn.GRUCell(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = inputs.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "        annotations = []\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
    "            hidden = self.gru(x, hidden)\n",
    "            annotations.append(hidden)\n",
    "\n",
    "        annotations = torch.stack(annotations, dim=1)\n",
    "        return annotations, hidden\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
    "        of a batch of sequences.\n",
    "\n",
    "        Arguments:\n",
    "            bs: The batch size for the initial hidden state.\n",
    "\n",
    "        Returns:\n",
    "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "        return to_var(torch.zeros(bs, self.hidden_size), self.opts.cuda)\n",
    "\n",
    "\n",
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = nn.GRUCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, annotations, hidden_init):\n",
    "        \"\"\"Forward pass of the non-attentional decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch. (batch_size x seq_len)\n",
    "            annotations: This is not used here. It just maintains consistency with the\n",
    "                    interface used by the AttentionDecoder class.\n",
    "            hidden_init: The hidden states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
    "            None\n",
    "        \"\"\"        \n",
    "        batch_size, seq_len = inputs.size()\n",
    "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
    "\n",
    "        hiddens = []\n",
    "        h_prev = hidden_init\n",
    "        for i in range(seq_len):\n",
    "            x = embed[:,i,:]  # Get the current time step input tokens, across the whole batch\n",
    "            h_prev = self.rnn(x, h_prev)  # batch_size x hidden_size\n",
    "            hiddens.append(h_prev)\n",
    "\n",
    "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
    "        \n",
    "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 100                                    \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.005                                  \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 20                                     \n",
      "                           decoder_type: rnn                                    \n",
      "                         attention_type:                                        \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('cod', 'odcay')\n",
      "('fill', 'illfay')\n",
      "('kingham', 'inghamkay')\n",
      "('recent', 'ecentray')\n",
      "('augment', 'augmentway')\n",
      "Num unique word pairs: 6387\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.334 | Val loss: 2.007 | Gen: ay insay onsay-ay-ay-ay insay onsay-ay-ay\n",
      "Epoch:   1 | Train loss: 1.893 | Val loss: 1.871 | Gen: estay-ay astingay onsay-ay-ay-ay-ay-ay ingay onsay-ay-ay-ay-ay-ay\n",
      "Epoch:   2 | Train loss: 1.755 | Val loss: 1.776 | Gen: estay ay oncontestay-ay-ay-ay ingay oonday-ay-ay-ay-ay-a\n",
      "Epoch:   3 | Train loss: 1.654 | Val loss: 1.719 | Gen: estay-ay-ay-ay-ay-ay away oontestway-ay-ay-ay- ingay-ay-ay oonsay-ay-ay-ay-ay-a\n",
      "Epoch:   4 | Train loss: 1.581 | Val loss: 1.676 | Gen: eray-ay-ay-ay-ay-ay- away oothestway-ay-ay-ay- ingay oontay-ay-ay-ay-ay-a\n",
      "Epoch:   5 | Train loss: 1.518 | Val loss: 1.609 | Gen: ersay-ay-ay-ay-ay-ay away ontingway-ayday ingay oodeshay\n",
      "Epoch:   6 | Train loss: 1.472 | Val loss: 1.641 | Gen: ersay-ay-ay-ay-ay-ay away-ayday ontestestway ingay onstestway-ayday\n",
      "Epoch:   7 | Train loss: 1.445 | Val loss: 1.536 | Gen: eray away ontingsway-ayday ingway onssay-ondway-ayday\n",
      "Epoch:   8 | Train loss: 1.395 | Val loss: 1.543 | Gen: eray-ayday away-ayday ontay-ingtay-ayday ingway oussshedway\n",
      "Epoch:   9 | Train loss: 1.360 | Val loss: 1.489 | Gen: eray-ayday away-ayday ontay-ingsway-ayday ingway orsesssway\n",
      "Epoch:  10 | Train loss: 1.325 | Val loss: 1.472 | Gen: eray-ayday away-ayday ontay-ingway-ayday ingay ousseshay\n",
      "Epoch:  11 | Train loss: 1.305 | Val loss: 1.485 | Gen: eray-ayday away-ayday onstay-ingway-ayday ingway orsesssay\n",
      "Epoch:  12 | Train loss: 1.289 | Val loss: 1.514 | Gen: ertay-ybay away-ayday ontay-ingway-ayday ingay-ayday orsesssay-ybay\n",
      "Epoch:  13 | Train loss: 1.299 | Val loss: 1.508 | Gen: eray-ayday aay-ay-ay-ayday ontanioncay-ontay-ay ingay-ayday orsessay-ybay\n",
      "Epoch:  14 | Train loss: 1.251 | Val loss: 1.439 | Gen: etay-ybay away-ayday ontray-ingsay-ayday ingway ousehay\n",
      "Epoch:  15 | Train loss: 1.222 | Val loss: 1.409 | Gen: etay-ybay away-ay ontancenestay-yay ingway oy-kay-ay-ayday\n",
      "Epoch:  16 | Train loss: 1.201 | Val loss: 1.393 | Gen: etay-ybay away-yay ontingsay-ingay-ayda ingway oy-kay-ay-ayday\n",
      "Epoch:  17 | Train loss: 1.176 | Val loss: 1.391 | Gen: etay-orway away-yway ontangnionssay-orway ingway ousehay\n",
      "Epoch:  18 | Train loss: 1.161 | Val loss: 1.491 | Gen: etay-orway away-yeay ontingay-ingay-angay ingay oy-oushay\n",
      "Epoch:  19 | Train loss: 1.147 | Val loss: 1.359 | Gen: ethay away-ingway ontingay-onsay-onsay ingway orrenesedray\n",
      "Epoch:  20 | Train loss: 1.133 | Val loss: 1.349 | Gen: etay away-ybay ontingay-earedway ingay-ayday orkerenceway\n",
      "Epoch:  21 | Train loss: 1.135 | Val loss: 1.450 | Gen: ethay aaiseway ontingsay-onsay-inga isedway ol-oushedway\n",
      "Epoch:  22 | Train loss: 1.124 | Val loss: 1.337 | Gen: ethay away-yeay ontanionstay-oveway issway orkentway\n",
      "Epoch:  23 | Train loss: 1.095 | Val loss: 1.398 | Gen: ethay away-yeay ontingay-ingay-ay-ay iseway orkenesedray\n",
      "Epoch:  24 | Train loss: 1.080 | Val loss: 1.317 | Gen: ethay aay-igay-ybay onsingingsay-ontay-o iseway oringfay\n",
      "Epoch:  25 | Train loss: 1.055 | Val loss: 1.311 | Gen: ethay aay-yearay oninteruningway-ybay issay orkenedsay\n",
      "Epoch:  26 | Train loss: 1.047 | Val loss: 1.308 | Gen: ethay aay-igay-ayday oninturingsay-ybay-a isedway oringlay-ybay\n",
      "Epoch:  27 | Train loss: 1.027 | Val loss: 1.292 | Gen: ethay aay-iway-yway onciningay-andway-aw inayday orkenedway\n",
      "Epoch:  28 | Train loss: 1.025 | Val loss: 1.285 | Gen: ethay aay-ingay onsinicutionsay isedway orkelway\n",
      "Epoch:  29 | Train loss: 1.023 | Val loss: 1.319 | Gen: ethay aay-eay-ayday ondingay-ingsay issay orkelay-ybay\n",
      "Epoch:  30 | Train loss: 1.006 | Val loss: 1.289 | Gen: ethay aay-igay-ybay oncintestay-ouseway issay orleshingway\n",
      "Epoch:  31 | Train loss: 0.995 | Val loss: 1.247 | Gen: ethay aay-ingway ondingancetingway isay orkenay\n",
      "Epoch:  32 | Train loss: 0.979 | Val loss: 1.251 | Gen: ethay aay-igay onsiniontay-omentway issay orleshingway\n",
      "Epoch:  33 | Train loss: 0.976 | Val loss: 1.256 | Gen: ethay aay-iway-ybay oncintestay-omeaway isay orkenedsay\n",
      "Epoch:  34 | Train loss: 0.971 | Val loss: 1.253 | Gen: ethay aainay onsiniontancenay isay orkelway-ybay\n",
      "Epoch:  35 | Train loss: 0.965 | Val loss: 1.261 | Gen: ethay aainghay ontingingsay-ayday issay orkenedway\n",
      "Epoch:  36 | Train loss: 0.955 | Val loss: 1.223 | Gen: ethay aaingay oncitingingssay issay origessway\n",
      "Epoch:  37 | Train loss: 0.938 | Val loss: 1.212 | Gen: ethay aay-iway-ybay oncitiingsay-omway-a issay orkenedway\n",
      "Epoch:  38 | Train loss: 0.925 | Val loss: 1.203 | Gen: ethay aaieseway oncitingingsay-ayday issay orkenedway\n",
      "Epoch:  39 | Train loss: 0.920 | Val loss: 1.218 | Gen: ethay aaieseway oncitingsay-indway-a idsay orkelway-yeay\n",
      "Epoch:  40 | Train loss: 0.921 | Val loss: 1.247 | Gen: ethay airway oncitiingsay-oomally issay orkenceway\n",
      "Epoch:  41 | Train loss: 0.924 | Val loss: 1.203 | Gen: ethay aay-igay-omway oncitionsay-ompay-ay issway orkenedway\n",
      "Epoch:  42 | Train loss: 0.914 | Val loss: 1.235 | Gen: ethay aaiesedway onsinicutionay-omway issay orkellyway\n",
      "Epoch:  43 | Train loss: 0.912 | Val loss: 1.194 | Gen: ethay airway oncitingsay-omway-ay issay orkenedway\n",
      "Epoch:  44 | Train loss: 0.891 | Val loss: 1.162 | Gen: ethay airway oncitiingsway ispay orkenedway\n",
      "Epoch:  45 | Train loss: 0.876 | Val loss: 1.161 | Gen: ethay aay-igray oncitiingsway ispay orkellway-ybay\n",
      "Epoch:  46 | Train loss: 0.876 | Val loss: 1.216 | Gen: ethay airway oncitingsay issway orkencay\n",
      "Epoch:  47 | Train loss: 0.897 | Val loss: 1.242 | Gen: ethay airway oningingsay ispay orkenedway\n",
      "Epoch:  48 | Train loss: 0.885 | Val loss: 1.169 | Gen: ethay aay-ighay oncitingingsway issay orgeredway\n",
      "Epoch:  49 | Train loss: 0.858 | Val loss: 1.173 | Gen: ethay airway oncitiingspay issay orkenedway\n",
      "Epoch:  50 | Train loss: 0.850 | Val loss: 1.197 | Gen: ethay airway oncitiingsay-ay-ayda issay orkenedway\n",
      "Epoch:  51 | Train loss: 0.843 | Val loss: 1.167 | Gen: ethay airway oncitiingsway ispay orkenedway\n",
      "Epoch:  52 | Train loss: 0.842 | Val loss: 1.180 | Gen: ethay airway ontinioutionsway issay orkencay\n",
      "Epoch:  53 | Train loss: 0.837 | Val loss: 1.171 | Gen: ethay airway oncitiingsway ispay orkenedway\n",
      "Epoch:  54 | Train loss: 0.835 | Val loss: 1.207 | Gen: ethay airway oninicutionsway ispay orkelay-ayday\n",
      "Epoch:  55 | Train loss: 0.828 | Val loss: 1.161 | Gen: ethay airway onqutienionableway ispay orkenceway\n",
      "Epoch:  56 | Train loss: 0.834 | Val loss: 1.185 | Gen: ethay airway ontingioningway issway orkenedway\n",
      "Epoch:  57 | Train loss: 0.822 | Val loss: 1.163 | Gen: ethay airway onciitionableway issway orkenedway\n",
      "Epoch:  58 | Train loss: 0.813 | Val loss: 1.168 | Gen: ethay airway oncitiingsay-ayday ispay orkenedway\n",
      "Epoch:  59 | Train loss: 0.811 | Val loss: 1.178 | Gen: ethay airway onciniturenedway issway orkenedway\n",
      "Epoch:  60 | Train loss: 0.811 | Val loss: 1.156 | Gen: ethay airway onciitioncay ispay orkedway\n",
      "Epoch:  61 | Train loss: 0.797 | Val loss: 1.131 | Gen: ethay airway oncituinedcay ispay orkenedway\n",
      "Epoch:  62 | Train loss: 0.797 | Val loss: 1.239 | Gen: ethay airway onitunioningcay ispay orkentay\n",
      "Epoch:  63 | Train loss: 0.810 | Val loss: 1.144 | Gen: ethay airway oncinitulingway ispay orkenedway\n",
      "Epoch:  64 | Train loss: 0.797 | Val loss: 1.134 | Gen: ethay airway oncitingpay issway orkenedway\n",
      "Epoch:  65 | Train loss: 0.802 | Val loss: 1.171 | Gen: ethay airway onquinestay-impway ispay orkenedway\n",
      "Epoch:  66 | Train loss: 0.799 | Val loss: 1.237 | Gen: ethay airway ondicituliencay ispay orkinglay\n",
      "Epoch:  67 | Train loss: 0.793 | Val loss: 1.166 | Gen: ethay airway oninticepay-ayday ispay orkelay\n",
      "Epoch:  68 | Train loss: 0.792 | Val loss: 1.174 | Gen: ethay airway onciitionay-oadway ispay orikeway\n",
      "Epoch:  69 | Train loss: 0.781 | Val loss: 1.203 | Gen: ethay airway onginguationcay ispay orkenedway\n",
      "Epoch:  70 | Train loss: 0.777 | Val loss: 1.150 | Gen: ethay airway onictienionay ispay orkenedway\n",
      "Epoch:  71 | Train loss: 0.769 | Val loss: 1.137 | Gen: ethay airway ondicutionionway ispay orkenedway\n",
      "Epoch:  72 | Train loss: 0.763 | Val loss: 1.154 | Gen: ethay airway onciitionaceway ispay orkedway\n",
      "Epoch:  73 | Train loss: 0.751 | Val loss: 1.132 | Gen: ethay airway onquinesingtay ispay orkenedway\n",
      "Epoch:  74 | Train loss: 0.750 | Val loss: 1.129 | Gen: ethay airway onicpeptionay-ayday ispay orkenay\n",
      "Epoch:  75 | Train loss: 0.751 | Val loss: 1.116 | Gen: ethay airway oncitiingnay issway orkenedcay\n",
      "Epoch:  76 | Train loss: 0.746 | Val loss: 1.105 | Gen: ethay airway oncinitulingway ispay orkinglay\n",
      "Epoch:  77 | Train loss: 0.743 | Val loss: 1.118 | Gen: ethay airway oncitiingpay issway orkenedcay\n",
      "Epoch:  78 | Train loss: 0.742 | Val loss: 1.172 | Gen: ethay airway oncinitulingway ispay okerledway\n",
      "Epoch:  79 | Train loss: 0.742 | Val loss: 1.121 | Gen: ethay airway onciniutionay ispay orkenay\n",
      "Epoch:  80 | Train loss: 0.765 | Val loss: 1.240 | Gen: ethay airway ontingingpay-omway ispay orkenfay\n",
      "Epoch:  81 | Train loss: 0.774 | Val loss: 1.200 | Gen: ethay airway onciinionay-acay issway orkinglay\n",
      "Epoch:  82 | Train loss: 0.743 | Val loss: 1.098 | Gen: ethay airway oncitiingpay ispay okelyhay\n",
      "Epoch:  83 | Train loss: 0.726 | Val loss: 1.130 | Gen: ethay airway onquinientay ispay okenhay\n",
      "Epoch:  84 | Train loss: 0.721 | Val loss: 1.168 | Gen: ethay airway onciitionay-ayday ispay orkenay\n",
      "Epoch:  85 | Train loss: 0.726 | Val loss: 1.130 | Gen: ethay airway onquinationmedway ispay orkenay\n",
      "Epoch:  86 | Train loss: 0.734 | Val loss: 1.112 | Gen: ethay airway oncitiingway ispay orkinglay\n",
      "Epoch:  87 | Train loss: 0.720 | Val loss: 1.093 | Gen: ethay airway oncinitulenceway issway orkenay\n",
      "Epoch:  88 | Train loss: 0.722 | Val loss: 1.092 | Gen: ethay airway onciationionsway issway orkeneway\n",
      "Epoch:  89 | Train loss: 0.720 | Val loss: 1.135 | Gen: ethay airway oncinientay isday okenhay\n",
      "Epoch:  90 | Train loss: 0.711 | Val loss: 1.096 | Gen: ethay airway onciitionay-ayday issway orkenay\n",
      "Epoch:  91 | Train loss: 0.708 | Val loss: 1.139 | Gen: ethay airway onciationingway ispay okenfay\n",
      "Epoch:  92 | Train loss: 0.705 | Val loss: 1.077 | Gen: ethay airway onciationionay issway okeredway\n",
      "Epoch:  93 | Train loss: 0.698 | Val loss: 1.126 | Gen: ethay airway oncinitulientway ispay orkinglay\n",
      "Epoch:  94 | Train loss: 0.697 | Val loss: 1.084 | Gen: ethay airway onciitionay-ayday issway orkenay\n",
      "Epoch:  95 | Train loss: 0.693 | Val loss: 1.149 | Gen: ethay airway onciationingway ispay okenhay\n",
      "Epoch:  96 | Train loss: 0.698 | Val loss: 1.091 | Gen: ethay airway onciautionsingway issway okeredway\n",
      "Epoch:  97 | Train loss: 0.691 | Val loss: 1.137 | Gen: ethay airway oncinientingway ispay orkinglay\n",
      "Epoch:  98 | Train loss: 0.689 | Val loss: 1.080 | Gen: ethay airway oncieniontay-ayday issway orkenay\n",
      "Epoch:  99 | Train loss: 0.686 | Val loss: 1.108 | Gen: ethay airway oncinitulingway ispay okelyhay\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway oncinitulingway ispay okelyhay\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "args = AttrDict()\n",
    "args_dict = {\n",
    "              'cuda':True, \n",
    "              'nepochs':100, \n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':0.005, \n",
    "              'lr_decay':0.99,\n",
    "              'batch_size':64, \n",
    "              'hidden_size':20, \n",
    "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
    "              'attention_type': '',  # options: additive / scaled_dot\n",
    "}\n",
    "args.update(args_dict)\n",
    "\n",
    "print_opts(args)\n",
    "rnn_encoder, rnn_decoder = train(args)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, rnn_decoder, None, args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\t\tthe air conditioning is working \n",
      "translated:\teeverereway\n"
     ]
    }
   ],
   "source": [
    "translated = translate_sentence(\"reverie\", rnn_encoder, rnn_decoder, None, args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fd8ee9bbc5624416ab410f5da1a0977cacaac913af6e0212055e5004ff35012"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
